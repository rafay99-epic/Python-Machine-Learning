{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BeautifulSoup4 once.\n",
    "# !pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data acquisition from a webpage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Using the Requests library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The URL to get the text data from.\n",
    "res = rq.get(\"https://en.wikipedia.org/wiki/Machine_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the status code is 200, then OK.\n",
    "# If the status code is 404, then it was not possible to locate the resource.\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The header as a dictionary.\n",
    "my_header = dict(res.headers)\n",
    "my_header.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some header values.\n",
    "print(my_header['Date'])\n",
    "print(my_header['Content-Type'])\n",
    "print(my_header['Content-language'])\n",
    "print(my_header['Content-Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the whole data.\n",
    "# Not easily intelligible.\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Using the BeautifulSoup4 library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use BeautifulSoup4 to parse the HTML.\n",
    "# There are 3 parsers: 'lxml', 'html5lib', 'html.parser'\n",
    "soup = bs4.BeautifulSoup(res.text, 'html.parser')     # Returns a BeautifulSoup object. Use 'html.parser'\n",
    "print(soup.prettify())                                # Output in a more readable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the text content from all the paragraphs.\n",
    "x=soup.find_all('p')\n",
    "n = len(x)\n",
    "paragraphs = ''                              # Initialize an empty string.\n",
    "for i in range(n):\n",
    "    paragraphs += x[i].text.strip() + '\\n'   # Carriage return at the end of each paragraph.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the result.\n",
    "print(paragraphs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
