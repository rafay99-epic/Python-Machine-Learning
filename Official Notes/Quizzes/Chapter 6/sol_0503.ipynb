{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz #0503 (Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Data Augmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the following questions by providing Python code:\n",
    "#### Objectives:\n",
    "- Code the helper functions.\n",
    "- Optimize and test a predictive model of your choice.\n",
    "- Carry out data aumentation in order to improve the predictive accuracy when the given training data is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "warnings.filterwarnings(action='ignore')                  # Turn off the warnings.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data:\n",
    "The explanation on the original data can be found [here](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "- The data we will be using is a small subset of the original data with only 100 observations.\n",
    "- Each observation is the \"flattened\" version of a image.\n",
    "- The first column corresponds to the label (Y).\n",
    "- The image size is 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training and testing data separately.\n",
    "data_train = pd.read_csv('data_mnist_train_100.csv', header=None,encoding='latin1')\n",
    "data_test = pd.read_csv('data_mnist_test_100.csv', header=None,encoding='latin1')\n",
    "\n",
    "# Scale and split the data set into X and Y.\n",
    "X_train = np.array((data_train.iloc[:,1:]/255.0)*0.99+0.01)\n",
    "X_test = np.array((data_test.iloc[:,1:]/255.0)*0.99+0.01)\n",
    "Y_train = np.array(data_train.iloc[:,0])\n",
    "Y_test = np.array(data_test.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1). Code the helper function 'show_data()' that visualizes each given observation. HINT: use matplotlib.pyplot.imshow() and scipy.ndimage.interpolation()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(X, Y, n, angle=0):\n",
    "    image_matrix = X[n,:].reshape((28,28))\n",
    "    image_matrix = rotate(image_matrix, angle, cval=0.01, reshape=False)\n",
    "    imax = image_matrix.max()\n",
    "    imin = image_matrix.min()\n",
    "    image_matrix = ((image_matrix-imin)/(imax-imin))*0.99+0.01\n",
    "    plt.imshow(image_matrix, cmap='Greys',interpolation='None')\n",
    "    print(Y[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1.\n",
    "show_data(X_train, Y_train,10,+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2.\n",
    "show_data(X_train, Y_train,10,-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3.\n",
    "show_data(X_train, Y_train,77,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2). Choose an algorithm and carry out the predictive analysis.\n",
    "\n",
    "- Optimize the hyperparameter(s).\n",
    "- Calculate the accuracy.\n",
    "- Is the accuracy high enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_grid = np.arange(30, 101, 10)\n",
    "depth_grid = np.arange(20, 51, 2)\n",
    "parameters = {'n_estimators': estimator_grid, 'max_depth': depth_grid}\n",
    "gridCV = GridSearchCV(RandomForestClassifier(), param_grid=parameters, cv=10)\n",
    "gridCV.fit(X_train, Y_train)\n",
    "best_n_estim = gridCV.best_params_['n_estimators']\n",
    "best_depth = gridCV.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest best n estimator : \" + str(best_n_estim))\n",
    "print(\"Random Forest best depth : \" + str(best_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_best = RandomForestClassifier(max_depth=best_depth,n_estimators=best_n_estim,random_state=3)\n",
    "RF_best.fit(X_train, Y_train);\n",
    "Y_pred = RF_best.predict(X_test)\n",
    "print( \"Random Forest best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3). Code the helper function 'rotate_data()' that rotates each given observation by an angle. HINT: use scipy.ndimage.interpolation()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_data(X, angle=0):\n",
    "    image_matrix = X.reshape((28,28))\n",
    "    image_matrix = rotate(image_matrix, angle, cval=0.01, reshape=False)\n",
    "    imax = image_matrix.max()\n",
    "    imin = image_matrix.min()\n",
    "    image_matrix = ((image_matrix-imin)/(imax-imin))*0.99+0.01\n",
    "    return image_matrix.reshape((1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4). Augment the training dataset.\n",
    "- Increase the size of the training dataset by introducing slight rotations (clockwise and counterclockwise).\n",
    "- Use the 'rotate_data()' function defined in the previous step.\n",
    "- No need to augment the testing dataset.\n",
    "- Target approximately five fold aumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_rows = X_train.shape[0]\n",
    "N_cols = X_train.shape[1]\n",
    "X_train_aug = np.empty((0,N_cols))\n",
    "Y_train_aug = np.array([])\n",
    "for angle in [-10,-5,0,5,10]:\n",
    "    for n in range(N_rows):\n",
    "        a_row = X_train[n,:]\n",
    "        a_y = Y_train[n]\n",
    "        X_train_aug = np.concatenate((X_train_aug,rotate_data(a_row,angle)),axis=0)\n",
    "        Y_train_aug = np.append(Y_train_aug, a_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5). Redo the predictive analysis with the augmented training dataset.\n",
    "\n",
    "- Use the same algorithm as in the step 2).\n",
    "- Calculate the accuracy.\n",
    "- Has the accuracy gone up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_best = RandomForestClassifier(max_depth=best_depth,n_estimators=best_n_estim,random_state=123)\n",
    "RF_best.fit(X_train_aug, Y_train_aug);\n",
    "Y_pred = RF_best.predict(X_test)\n",
    "print( \"Random Forest accuracy with the aumented training data : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
