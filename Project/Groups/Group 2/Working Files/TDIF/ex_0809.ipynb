{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Practice #0809"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Word embedding (Word2Vec):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install once if necessary.\n",
    "#!pip install gensim\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import urllib\n",
    "import bs4 as bs\n",
    "import warnings\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "warnings.filterwarnings('ignore')\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Download the text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the source.\n",
    "source = urllib.request.urlopen('https://en.wikipedia.org/wiki/Machine_learning').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful soup object.\n",
    "soup = bs.BeautifulSoup(source,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a long string. \n",
    "my_text = \"\"\n",
    "for paragraph in soup.find_all('p'):\n",
    "    my_text += paragraph.text\n",
    "print(my_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Preprocessing of the text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = my_text.lower()\n",
    "my_text = re.sub(r'\\[[0-9]*\\]',' ', my_text)\n",
    "my_text = re.sub(r'\\W',' ', my_text)\n",
    "#my_text = re.sub(r'\\s+',' ',my_text)\n",
    "my_text = re.sub(r'\\d+',' ',my_text)\n",
    "my_text = re.sub(r'\\s+',' ',my_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sentences = nltk.sent_tokenize(my_text)\n",
    "my_words_0=[]\n",
    "for a_sentence in my_sentences:\n",
    "    my_words_0 += nltk.word_tokenize(a_sentence)\n",
    "my_words_0 = [a_word for a_word in my_words_0 if len(a_word)>2 ]\n",
    "my_words_0 = [a_word for a_word in my_words_0 if a_word not in stopwords.words('english')]\n",
    "my_words_0 = [my_words_0]    # Required by Word2Vec.\n",
    "len(my_words_0[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Train the Word2Vec model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Word2Vec(my_words_0, size = 100, min_count=1)\n",
    "my_words = my_model.wv.vocab\n",
    "len(my_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Embedding vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dense vector corresponding to 'machine'.\n",
    "my_vector = my_model.wv['machine']\n",
    "print(\"Length = \" + str(my_vector.shape[0]))\n",
    "print(\"-\"*100)\n",
    "print(my_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Most similar words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.wv.most_similar('learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.wv.most_similar('artificial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operation:\n",
    "# global - cooling + warming = ???\n",
    "my_model.wv.most_similar(positive=['machine','human'], negative= ['learning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using a pre-trained model from Google:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [\"GoogleNews-vectors-negative300.bin\"](https://docs.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download) and uncompress. <br>\n",
    "**Caution**: Size compressed ~ 1.6 Gb, uncompressed ~ 3.5 Gb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the directory where the downloaded file is located. \n",
    "# os.chdir(r'~~')                # Please, replace the path with your own.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file.\n",
    "filename = \"GoogleNews-vectors-negative300.bin\"\n",
    "a_model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most similar words to 'king' or 'kings'.\n",
    "a_model.most_similar(['king','kings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operation: queen(queens) - woman(women) + man(men) = ???\n",
    "a_model.most_similar(positive=['queen','queens','man','men'], negative= ['woman','women'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
