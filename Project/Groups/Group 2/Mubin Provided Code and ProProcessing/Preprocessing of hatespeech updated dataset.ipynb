{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e86118b",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6c1984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import re\n",
    "from wordsegment import load, segment, clean\n",
    "load() #loading segment\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c8cab",
   "metadata": {},
   "source": [
    "# Reading the dataset and Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe14d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D2.csv',header = 'infer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac9d0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8f2cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows and columns i.e. dimension of the dataset:  (31962, 3)\n",
      "\n",
      "column names of the dataset:  Index(['id', 'label', 'tweet'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('number of rows and columns i.e. dimension of the dataset: ',df.shape)\n",
    "print('\\ncolumn names of the dataset: ',df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72eb596",
   "metadata": {},
   "source": [
    "## Separating the tweets and class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "652a8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassLabel = df['tweet']\n",
    "tweets = df.tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb261c7",
   "metadata": {},
   "source": [
    "### Plotting the class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1f254",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6, 6))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plt.hist(ClassLabel, bins=5, color='Green', density=False, edgecolor='black')\n",
    "plt.title('HateSpeech Classification Initial Histogram')\n",
    "plt.xlabel('Classes \\n0 - HateSpeech, 1 - Offensive Laguage')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc97597",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50953544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         @user when a father is dysfunctional and is s...\n",
      "1        @user @user thanks for #lyft credit i can't us...\n",
      "2                                      bihday your majesty\n",
      "3        #model   i love u take with u all the time in ...\n",
      "4                   factsguide: society now    #motivation\n",
      "                               ...                        \n",
      "31957    ate @user isz that youuu?ðððððð...\n",
      "31958      to see nina turner on the airwaves trying to...\n",
      "31959    listening to sad songs on a monday morning otw...\n",
      "31960    @user #sikh #temple vandalised in in #calgary,...\n",
      "31961                     thank you @user for you follow  \n",
      "Name: tweet, Length: 31962, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d57d32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corp = []\n",
    "pat = re.compile('^[A-Za-z0-9]+')\n",
    "patr = '([?ð\\x9f\\x98\\x8dð\\x9f\\x98\\x8dð\\x9f\\x98\\x8dð\\x9f\\x98\\x8dð\\x9f\\x98\\x8dð\\x9f\\x98\\x8dð\\x9f\\x98\\x8dð\\x9f\\x98\\x8dð\\x9f\\x98\\x8dâ\\x9d¤ï¸\\x8f])+\\x80¦'\n",
    "for i in range(0,len(tweets)):\n",
    "    New_String = re.sub(pat,'',tweets[i])\n",
    "    New_String = \"\".join(New_String)\n",
    "    New_String = re.sub(patr,'',tweets[i])\n",
    "    New_String = \"\".join(New_String)\n",
    "    corp.append(New_String)\n",
    "print(corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c2fca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25d6719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ClassLabel'] = ClassLabel \n",
    "df1.columns = ['tweets','ClassLabel']\n",
    "df1.to_csv(r'/home/scarlet-speedester/Documents/Book1.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef94b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_urls_regExp = '(https?:\\/\\/t\\.co\\/\\w+)'\n",
    "char_regExp = '[,\\?:\\|]'\n",
    "quoteHtml_regExp = '(&#8220;)|(&#8221;)'\n",
    "andHtml_regExp = '(&amp;)'\n",
    "emo_happy = '[&#...[514;]$]+|[&#...[513;]$]+'\n",
    "for i in range(0, len(tweets)):\n",
    "    tweetsUpdated = re.sub(num_urls_regExp, '',tweets[i]).split()         # 3.1.1 - removing URLS & numbers\n",
    "    tweetsUpdated = \" \".join(tweetsUpdated)                               # joining the string after split\n",
    "    tweetsUpdated = re.sub(andHtml_regExp,'and',tweetsUpdated).split()    # replacemnt of html_and_code with text and\n",
    "    tweetsUpdated = \" \".join(tweetsUpdated)                               # joining the string after split\n",
    "    tweetsUpdated = re.sub(char_regExp, ' ',tweetsUpdated).split()               # 3.1.1 - removing ,:|?\n",
    "    tweetsUpdated = \" \".join(tweetsUpdated)                               # joining the string after split\n",
    "    tweetsUpdated = re.sub(quoteHtml_regExp,'',tweetsUpdated)             # removing quotation marks in html codes\n",
    "    tweetsUpdated = tweetsUpdated.lower().split()                         # 3.1.2 - converting to lower characters and removing spaces from left and right\n",
    "    tweetsUpdated = \" \".join(tweetsUpdated)                               # joining the string after split\n",
    "    tweetsUpdated = re.sub(emo_happy,'happy',tweetsUpdated)\n",
    "#     tweetsUpdated = clean(tweetsUpdated)                                  # 3.1.3 - cleaning data for segmentation\n",
    "#     tweetsUpdated = segment(tweetsUpdated)                                # 3.1.3 - word segmentation using word segment module\n",
    "#     tweetsUpdated = \" \".join(tweetsUpdated)                               # joining the string after split\n",
    "    corpus.append(tweetsUpdated)                                          # Inserting the updated tweets into a corpus i.e. list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd2c10d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"&#128129;&#128513;&#128586;- lmao my nigga . let's go half on a weed brownie &#128553; we will be laughing hard as hell in senior seminar\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[958]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1cdc2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acb6bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ClassLabel'] = ClassLabel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63a0f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = ['tweets','ClassLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d968eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(r'C:\\Users\\MrPablo\\Desktop\\updated_dataframe_with_no_urls_no_four_characters_and_numbers_and_in_lower_case_htmlAnd_htmlQuote.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e262ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
