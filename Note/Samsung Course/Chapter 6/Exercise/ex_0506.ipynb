{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0506"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Compare the Tree-like algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_digits\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "warnings.filterwarnings(action='ignore')                  # Turn off the warnings.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Read in data and explore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the description on the data.\n",
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The explanatory variables.\n",
    "X = data['data']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The response variable.\n",
    "Y = data['target']\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a visualization function.\n",
    "def show_data(X, Y, n, angle=0):\n",
    "    print(Y[n])\n",
    "    image_matrix = X[n,:].reshape((8,8))                                        # Reshape from 1D to 2D matrix.\n",
    "    image_matrix = rotate(image_matrix, angle, cval=0.01, reshape=False)        # Rotate if wanted.       \n",
    "    plt.imshow(image_matrix, cmap='Greys',interpolation='None')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [15,29,99]:\n",
    "    show_data(X,Y,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Data pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max scaling to the whole dataset.\n",
    "X_min = X.min()\n",
    "X_max = X.max()\n",
    "X_range = X_max - X_min\n",
    "X = (X - X_min)/X_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Classification with Tree (optimized hyperparameters):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We optimize only some of the hyperparameters due to time considerataion. Students are encouraged to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_grid = np.arange(1,21)\n",
    "min_samples_leaf_grid = np.arange(2,31,2)\n",
    "max_leaf_nodes_grid = np.arange(2,51,2)\n",
    "parameters = {'max_depth':depth_grid, 'min_samples_leaf':min_samples_leaf_grid, 'max_leaf_nodes':max_leaf_nodes_grid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridCV = GridSearchCV(DecisionTreeClassifier(), parameters, cv=10, n_jobs = -1)\n",
    "gridCV.fit(X_train, Y_train)\n",
    "best_depth = gridCV.best_params_['max_depth']\n",
    "best_min_samples_leaf = gridCV.best_params_['min_samples_leaf']\n",
    "best_max_leaf_nodes = gridCV.best_params_['max_leaf_nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tree best max_depth : \" + str(best_depth))\n",
    "print(\"Tree best min_samples_leaf : \" + str(best_min_samples_leaf))\n",
    "print(\"Tree best max_leaf_nodes : \" + str(best_max_leaf_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_best = DecisionTreeClassifier(max_depth=best_depth,min_samples_leaf=best_min_samples_leaf,max_leaf_nodes=best_max_leaf_nodes)\n",
    "DTC_best.fit(X_train, Y_train)\n",
    "Y_pred = DTC_best.predict(X_test)\n",
    "print( \"Tree best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Classification with Random Forest (optimized hyperparameters):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We optimize only some of the hyperparameters due to time considerataion. Students are encouraged to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_grid = np.arange(20, 50,2)\n",
    "depth_grid = np.arange(1, 10)\n",
    "min_samples_leaf_grid = np.arange(10,21,2)\n",
    "parameters = {'n_estimators': n_estimators_grid, 'max_depth': depth_grid, 'min_samples_leaf':min_samples_leaf_grid}\n",
    "gridCV = GridSearchCV(RandomForestClassifier(), param_grid=parameters, cv=10, n_jobs=-1)\n",
    "gridCV.fit(X_train, Y_train)\n",
    "best_n_estim = gridCV.best_params_['n_estimators']\n",
    "best_depth = gridCV.best_params_['max_depth']\n",
    "best_min_samples_leaf = gridCV.best_params_['min_samples_leaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest best n_estimator : \" + str(best_n_estim))\n",
    "print(\"Random Forest best max_depth : \" + str(best_depth))\n",
    "print(\"Random Forest best min_samples_leaf : \" + str(best_min_samples_leaf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_best = RandomForestClassifier(n_estimators=30,max_depth=best_depth,min_samples_leaf=best_min_samples_leaf,random_state=123)\n",
    "RF_best.fit(X_train, Y_train)\n",
    "Y_pred = RF_best.predict(X_test)\n",
    "print( \"Random Forest best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Classification with AdaBoost (optimized hyperparameters):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We optimize only some of the hyperparameters due to time considerataion. Students are encouraged to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_max_depth = 9                                               # Fixed.\n",
    "my_learn_rate = 0.01                                           # Fixed.\n",
    "n_estimators_grid = np.arange(50, 81, 2)\n",
    "parameters = {'n_estimators': n_estimators_grid}\n",
    "AB = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=my_max_depth), learning_rate=my_learn_rate)      # Instantiate an estimator.\n",
    "gridCV = GridSearchCV(AB, param_grid=parameters, cv=10, n_jobs = -1)\n",
    "gridCV.fit(X_train, Y_train)\n",
    "best_n_estim = gridCV.best_params_['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AdaBoost best n estimator : \" + str(best_n_estim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_best = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=my_max_depth),n_estimators=best_n_estim,learning_rate=my_learn_rate,random_state=123)\n",
    "AB_best.fit(X_train, Y_train)\n",
    "Y_pred = AB_best.predict(X_test)\n",
    "print( \"AdaBoost best accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
